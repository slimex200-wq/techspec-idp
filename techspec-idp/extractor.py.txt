import base64
import requests
import json
import mimetypes
from pdf2image import convert_from_path
import os

OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")

def encode_file(path):
    with open(path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")

def pdf_to_images(pdf_path):
    pages = convert_from_path(pdf_path, dpi=200)
    paths = []
    for i, p in enumerate(pages):
        out = f"/tmp/page_{i+1}.jpg"
        p.save(out, "JPEG")
        paths.append(out)
    return paths

def call_gpt(base64_data, mime, prompt):
    url = "https://api.openai.com/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "gpt-4o",
        "response_format": {"type": "json_object"},
        "messages": [
            {"role": "system", "content": prompt},
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "문서에서 JSON만 추출하세요."},
                    {
                        "type": "input_image",
                        "image_url": f"data:{mime};base64,{base64_data}"
                    }
                ]
            }
        ]
    }
    r = requests.post(url, headers=headers, json=payload)
    r.raise_for_status()
    return json.loads(r.json()["choices"][0]["message"]["content"])

def extract_document(path, prompt):
    mime, _ = mimetypes.guess_type(path)

    if mime == "application/pdf":
        images = pdf_to_images(path)
        all_pages = []
        for img in images:
            b64 = encode_file(img)
            page = call_gpt(b64, "image/jpeg", prompt)
            all_pages.append(page)
        return {"pages": all_pages}

    else:
        b64 = encode_file(path)
        return call_gpt(b64, mime, prompt)
